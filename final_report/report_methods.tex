\section{Exploration of Potential Methods and Their Suitability}
\label{sec:method_exploration}
The four possible methods that can be used in this project are, as mentioned previously, raw signal simulation, rasterisation, ray tracing and a hybrid method. In this section I will cover their suitability as they relate to this project, as well as explore the methods of transforming SAR raw signals into an image.
\subsection{SAR Simulation Methods}
\subsubsection{Raw SAR Simulation}
This is the most robust form of simulation and the most accurate as the individual signals are simulated as well as their reflections. This does have some drawbacks as developing the system in the first place is likely to be quite complex. This system requires the implementation of a transmission and reception element (likely to be two separate functions for complexity reasons), a free-space element, an element to act as the target would in real life to accurately simulate the return signal, some sort of coordinate system to position both the target and the platform in free space and finally the linear FM waveform. These are all sections that, while the conceptual understanding of their operation is relatively easy to grasp given prior knowledge of how wireless communications and more specifically radar work, are not altogether simple in their implementation. Fortunately this would not be implemented blind thanks to Franceschetti \textit{et al.} 2003 \cite{franceschettiSARRawSignal2003} and all the foundational work that led to it however this work has been refined over the course of more than a decade, not several weeks, which is potentially the biggest limitation on how in-depth this implementation can go and the biggest roadblock against this particular method of simulation. 
\subsubsection{Rasterisation}
As previously mentioned, rasterisation is one approach to SAR simulation that does not require lengthy implementation processes as rasterisation is a standard process in image manipulation. In this case what would be required is devising some sort of transform from the 3-dimensional image simulated and the SAR output. This will not be true SAR as it is only the result of taking one image from one place and therefore will not truly be an accurate representation. As was discussed in Balz 2006 \cite{balzImprovedRealTimeSAR2006} and all related work this is a desirable outcome in the event that this SAR simulation is to be used as a real-time simulation in order to plan actual SAR imaging flights. In this project this isn't necessarily the case as my intention is to create a final product that is usable as a teaching aide, which would involve some sort of progression as the SAR image is taken. This isn't a particularly practical approach to be used with this in mind as it can be done instantly (or as near as to a human) and the image isn't built up over multiple measurements.
\subsubsection{Ray-tracing}
Ray-tracing is, in this case, somewhat of a hybrid method. As it doesn't simulate the free space and electromagnetic effects of the radar it isn't truly SAR however it works in a similar just inverted way. This is because the light beams (here analogous to the higher frequency EM waves) are projected from the observer (the receiver) and reflect off objects until they reach a source of illumination (the transmitter). This could be useful for teaching purposes as the method by which it works could be the same and then the image is built using similar image formation methods to those used by true SAR. The issue with this type of simulation is a relative lack of experience in it and some issues with the complexity of implementation. This is partially an issue with all three forms of simulation which will be covered in the following section, but also ray-tracing is known to be a very computationally intense form of visual rendering and requires a strong knowledge with three-dimensional rendering techniques to even begin to implement a version of this.
\subsubsection{3D Rendering Engines}
There is a problem common to all three of these potential methods, which is that no matter what they will require some form of 3D rendering engine, either to simulate the effect of the radar waves or ray-tracing, or to provide a 3D image base for the rasterisation transformation. Unsurprisingly none of the rendering engines currently commonly available are perfectly suited for this and many of the ones investigated were unusable for this case. Ideally some time would be allowed for creating a custom 3D modelling engine that would properly handle EM waves or equivalent. The closest to working appeared to be Blender \cite{foundationBlenderOrgHome}, an incredibly powerful modelling engine released under a GNU Public License by the Blender Foundation that has a Python scripting engine, however due to a lack of familiarity with this software it was decided that gaining a strong enough familiarity with the package would take too long to be practical in this project. The final approach chosen is discussed in Section \ref{subsec:approach_chosen}
%TODO extend these somewhat
\subsection{Image Forming Methods}
Raw SAR simulation requires an image formation method. This takes the overlapping received signals and time-multiplexes them to display an image that can be interpreted by a person, especially with multiple targets at the same range. There are multiple forms available and a few of them will be discussed here. These will all be the forms used for airborne (including space-based) platforms as there are some corrections required for ground-based systems that are irrelevant here although are covered in Guo and Dong (2016) \cite{guoModifiedOmegaKAlgorithm2016}, as well as in a practical sense on the blog of Henrik Forst√©n for both an Omega-K \cite{forstenSyntheticapertureRadarImaging2019} and Backprojection \cite{forstenBackprojectionBackpropagation2019} approach (both covered here, among others). All the algorithms will operate in similar ways however they all have strengths and weaknesses. 
\subsubsection{Omega-K ($\omega KA$)}
Omega-K is otherwise known as the range migration algorithm. It works by first Fourier transforming the received SAR signal into the frequency domain and then performing bulk compression, which is where the signal is multiplied by a reference function computed for a known range. A target is correctly focused at this reference range but targets not at this range are only partially focused. Following this, the signal undergoes Stolt interpolation, which re-maps the range frequency axis in order to bring targets away from the reference range into focus. It achieves this by transforming the range frequency so the phase is linear. This effectively removes all phase terms higher than the linear term, although these aren't ignored. Finally an inverse Fourier transform is performed on the signal to put it back into the image domain. For a more in depth explanation of how the Stolt mapping works, see Cumming \textit{et al.} 2003 \cite[section~3]{cummingInterpretationsOmegaKAlgorithm2003}. This approach does assume that the trajectory is completely straight so if this isn't achieved then the displayed image will be incorrect \cite{albuquerqueApplicationsTimeDomainBackProjection}. For this application this is not an issue of concern as the simulated airborne platform will always be travelling in a straight line but is worth keeping in mind for more general applications.
\subsubsection{Backprojection}
Backprojection uses a matched filter approach to get the difference between the expected return from the radar and the actual return from the radar and was originally developed for use in computer-aided tomography for medical reasons \cite{naComparisonBackProjectionRange2006}. This is generally performed in the time domain as opposed to the frequency domain due to the lack of assumptions that have to be made \cite{albuquerqueApplicationsTimeDomainBackProjection}. The way this works is the position of the platform is known in 3 dimensional space and so the expected return can be calculated based on the time delay from the reflected signal. The matched filter that this creates can then remove this from the received signal and the difference is due to an object that reflected the signal prematurely. There are some other sources of error in this case such as multiple bounces on the image or impreciseness in calculating the imaging platform position \cite{duerschBackprojectionSyntheticAperture2013}. This algorithm is not ideal as it is very computationally intensive and requires that the imaging geometry needs to be precisely known. This positioning can normally be estimated using an inertial navigation system so is not particularly difficult to obtain however it does need to be precise as this can make received images appear shifted from where they are actually positioned. As each pixel can be handled independently of the other pixels it is ideally suited for parallel computing so the computation time can be reduced significantly \cite{albuquerqueApplicationsTimeDomainBackProjection}.
\subsubsection{Range-Doppler (RDA)}
This algorithm is similar in process to $\omega KA$. It is implemented in the frequency domain but operates only in one dimension at a time, which improves the simplicity of the algorithm. The first step is range migration, which is where the raw data is Fourier transformed in the range dimension and multiplied with the range reference signal and transforms back to the image domain. This algorithm then performs a Fourier transform in the azimuth only, transforming to the range Doppler domain before performing a Range Cell Migration Correction (RCMC). This is to correct for the slant range to the target changing as the platform moves through space, meaning that the Doppler frequency of the target is different at different times and so appears at different ranges. The RCMC corrects for this by shifting each cell a set number of metres depending on its distance from the reference range \cite{parasharStudyRangeCell2015}. After this a matched filter for just the azimuth is used to perform azimuth compression and the whole image is returned to the image domain for visualisation \cite{dastgirProcessingSARData2007}. This algorithm was created in the 1970s and so is more basic than the Omega-K algorithm. In this case the RDA in an accurate form is somewhat equivalent to an approximate form of $\omega KA$, however RDA is often used in a less accurate form where the range compression is not varied according to either range or azimuth frequencies, and the accurate form of $\omega KA$ is more accurate than the approximate form \cite{cummingInterpretationsOmegaKAlgorithm2003}, so is a better choice for this application.
\subsubsection{Chirp Scaling (CSA)}
Chirp scaling is quite similar to RDA, and the difference is improving the RCMC by removing the interpolation required. It does this by applying a phase multiply in order to equalise the range migrations of all the targets. This Chirp scale factor is generally 1 for a satellite based SAR system and higher for aircraft based \cite{dastgirProcessingSARData2007}. This algorithm has an accuracy somewhere between that of the accurate and approximate $\omega KA$ and approximate $\omega KA$ is  roughly equivalent to CSA if there was no chirp scaling performed \cite{cummingInterpretationsOmegaKAlgorithm2003}.
\subsection{Discussion of Approaches Chosen and Reasoning}
\label{subsec:approach_chosen}
After carefully considering the approaches discussed above, the decision has been made to implement the SAR simulation using raw methods, specifically using the Simulink Phased Array Toolbox, with image formation performed using MATLAB. This is because the issues with implementing all the sections mentioned previously are removed and they are created in a far more robust way than would be possible to implement within the time available for this project. Simulink has been chosen for this because it's more tactile than the equivalent MATLAB code would be so is better for the desired outcome in this case which is to create a tool that can be used as a teaching aid while learning synthetic aperture radar. Simulink also gives access to the Simulink 3D Animation Toolbox, which allows for linking models to a 3D visualisation, which is similarly useful in a teaching environment. Simulink is not suited to image formation algorithms as they require all the data to be present at once, whereas Simulink works best when the data can be fed in over the length of the simulation. Therefore these will be implemented in MATLAB. In this case, both $\omega KA$ and backprojection will be implemented as the differences between the two will be interesting to observe, especially considering the data input will be identical. These have been chosen as they are more accurate than either CSA or RDA and so will give a better representation. Specifically $\omega KA$ will be implemented using the accurate version described in Cumming \textit{et al.} 2003 \cite{cummingInterpretationsOmegaKAlgorithm2003} and backprojection will be implemented based on the approach outlined in Yegulalp 1999 \cite{yegulalpFastBackprojectionAlgorithm1999} as this should provide better performance than standard backprojection algorithms.
\section{Desired Results and Outcomes}
The major desired outcome of this project is to have a Simulink model that can simulate a SAR system with one target, in such a way that it can be easily examined for teaching purposes. This model must output data so that a MATLAB script can read it in and perform at least one and more ideally two methods of image formation. This Simulink model must also feed into a Simulink 3D World in such a way that it is obvious what is happening in the model and provide a visual aid to the model when it is running. Extended from this it would be ideal if the dimensions of the target could be read in from the Simulink 3D World and used to update the radar cross section of the target within the Simulink model in a dynamic fashion. As another extension to this, a cone to visualise the antenna beam within the Simulink 3D World would be nice to have however is not completely necessary. Finally, the ability within the model to switch between stripmap and spotlight modes and have the cone within the 3D World update to match would be nice however again not strictly necessary. 
\section{Milestones}









































